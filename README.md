# ğŸ“˜ GestureTalk AI â€“ Sign Language to Speech Converter

# 

# GestureTalk AI is an intelligent real-time sign language recognition system built to improve communication between the deaf community and the hearing population. Using MediaPipe, TensorFlow, scikit-learn, and OpenCV, the system detects hand gestures via webcam and converts them instantly into text and speech.

# 

# ğŸš€ Features

# 

# âœ‹ Real-time gesture tracking using MediaPipe Hand Landmark Detection

# 

# ğŸ§  Custom-trained ML model for accurate sign classification

# 

# ğŸ¤ Text-to-Speech output for smooth communication

# 

# ğŸ¯ Supports multiple gestures with high accuracy

# 

# ğŸª¶ Lightweight, fast, and optimized for real-time performance

# 

# ğŸ§© Easy to extend with new gestures and models

# 

# ğŸ› ï¸ Tech Stack

# 

# Languages: Python

# Libraries:

# 

# MediaPipe

# 

# TensorFlow

# 

# scikit-learn

# 

# NumPy

# 

# OpenCV

# 

# pyttsx3 (for speech output)

# 

# ğŸ“ Project Structure

# GestureTalk-AI/

# â”‚â”€â”€ data/               # Dataset for gesture training

# â”‚â”€â”€ model/              # Saved ML model files

# â”‚â”€â”€ src/                # Main program code

# â”‚   â”œâ”€â”€ collect\_data.py

# â”‚   â”œâ”€â”€ train\_model.py

# â”‚   â”œâ”€â”€ recognize.py

# â”‚â”€â”€ README.md

# â”‚â”€â”€ requirements.txt

# 

# âš™ï¸ How It Works

# 

# MediaPipe detects hand landmarks (21 coordinates per hand).

# 

# Coordinates are converted into a numerical dataset.

# 

# A TensorFlow model is trained to classify gestures.

# 

# In real time, the model predicts the gesture shown to the camera.

# 

# The system displays the prediction and optionally speaks it aloud.
######How to RUN :-################################################
run this code to terminal 
   pip install -r requirements.txt
then use trainer.py create the data set 
then create the model using createModel.py



