# ğŸ“˜ GestureTalk AI


##

## GestureTalk AI is an intelligent real-time sign language recognition system built to improve communication between the deaf community and the hearing population. Using MediaPipe, TensorFlow, scikit-learn, and OpenCV, the system detects hand gestures via webcam and converts them instantly into text and speech.

##



# ğŸš€ Features

## Real-time hand tracking

## Fast and accurate gesture recognition

## âœ‹ Real-time gesture tracking using MediaPipe Hand Landmark Detection

## ğŸ§  Custom-trained ML model for accurate sign classification

## ğŸ¤ Text-to-Speech output for smooth communication

## ğŸ¯ Supports multiple gestures with high accuracy

## ğŸª¶ Lightweight, fast, and optimized for real-time performance

## ğŸ§© Easy to extend with new gestures and models
#
# ğŸ› ï¸ Technologies Used

## Python
## MediaPipe
## TensorFlow
## OpenCV
## NumPy
## scikit-learn
#
# ğŸ“ Project Structure

## GestureTalk-AI/
## â”‚â”€â”€ data/               # Dataset for gesture training
## â”‚â”€â”€ model/              # Saved ML model files
## â”‚â”€â”€ src/                # Main program code
## â”‚   â”œâ”€â”€ collect\_data.py
## â”‚   â”œâ”€â”€ train\_model.py
## â”‚   â”œâ”€â”€ recognize.py
## â”‚â”€â”€ README.md
## â”‚â”€â”€ requirements.txt

#
# âš™ï¸ How It Works

### 

## MediaPipe detects hand landmarks (21 coordinates per hand).

###

## Coordinates are converted into a numerical dataset.

### 

## A TensorFlow model is trained to classify gestures.

### 

## In real time, the model predicts the gesture shown to the camera.

### 

## The system displays the prediction and optionally speaks it aloud.

#
# ğŸš€ How to Run the Project
## âœ… Step 1: Install Dependencies
### Run this command in your terminal:
- `pip install -r requirements.txt`
## âœ… Step 2: Create the Dataset
### Use the trainer script to collect gesture data:
- `python trainer.py`
## âœ… Step 3: Train & Generate the Model
### After collecting data, train your model:
- `python createModel.py`
